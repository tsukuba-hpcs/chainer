start:data = comm.bcast_obj(data, max_buf_len=max_buf_len, root=0)
finish:data = comm.bcast_obj(data, max_buf_len=max_buf_len, root=0)
start:extensions initializer
finish:extensions initializer
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.bcast_data(target)
start:nccl_comm_id = mpi_comm.bcast(nccl_comm_id)
end:nccl_comm_id = mpi_comm.bcast(nccl_comm_id)
finish:self.communicator.bcast_data(target)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.print_report.PrintReport object at 0x2b4e7619ed30> extension
finish <chainer.training.extensions.print_report.PrintReport object at 0x2b4e7619ed30> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.print_report.PrintReport object at 0x2b4e7619ed30> extension
finish <chainer.training.extensions.print_report.PrintReport object at 0x2b4e7619ed30> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
start:optimizer.update(loss_func, *in_arrays) <class 'chainermn.optimizers._MultiNodeOptimizer'>
<class 'chainermn.communicators.pure_nccl_communicator.PureNcclCommunicator'>
start:self.communicator.allreduce_grad(target)
finish:self.communicator.allreduce_grad(target)
start:self.actual_optimizer.update(None, *args, **kwds)
finish:self.actual_optimizer.update(None, *args, **kwds)
finish:optimizer.update(loss_func, *in_arrays)
finish:update()
start <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
finish <chainer.training.extensions.log_report.LogReport object at 0x2b4e7619ec50> extension
start <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
finish <chainer.training.extensions.progress_bar.ProgressBar object at 0x2b4e7619ee80> extension
start:update()
start:batch = iterator.next()
finish:batch = iterator.next()
Traceback (most recent call last):
  File "/work/NBB/serihiro/local/lib/python3.6/multiprocessing/forkserver.py", line 196, in main
    _serve_one(s, listener, alive_r, old_handlers)
  File "/work/NBB/serihiro/local/lib/python3.6/multiprocessing/forkserver.py", line 234, in _serve_one
    write_unsigned(child_w, code)
  File "/work/NBB/serihiro/local/lib/python3.6/multiprocessing/forkserver.py", line 253, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/work/NBB/serihiro/local/lib/python3.6/multiprocessing/forkserver.py", line 196, in main
    _serve_one(s, listener, alive_r, old_handlers)
  File "/work/NBB/serihiro/local/lib/python3.6/multiprocessing/forkserver.py", line 234, in _serve_one
    write_unsigned(child_w, code)
  File "/work/NBB/serihiro/local/lib/python3.6/multiprocessing/forkserver.py", line 253, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
/work/NBB/serihiro/local/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 4 leaked semaphores to clean up at shutdown
  len(cache))
